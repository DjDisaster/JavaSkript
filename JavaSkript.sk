import:
	java.util.regex.Matcher
	java.util.regex.Pattern
	
function Token(s: string, o: object) :: nbt compound:
	replace all """" in {_o} with "\"""
	return nbt from "{Name:%{_s}%,Value:""%{_o}%""}"
	
function TokenType(token: nbt compound) :: string:
	return string tag "Name" of {_token}
	
function TokenValue(token: nbt compound) :: string:
	return string tag "Value" of {_token}
	
function SetTokenValue(token: nbt compound, o: object) :: nbt compound:
	set string tag "Value" of {_token} to {_o}

function Tokenise(s: string) :: nbt compounds:
	loop ({_s} split at nl):
		add Tokenised(loop-value, {_isExpressionParsing}) to {_tokens::*}
		
	return {_tokens::*}
		
function Tokenised(s: string, isExpressionParsing: boolean=false) :: nbt compounds:
	set {_length} to length of {_s}
	set {_currentIndexLowest} to 0
	set {_currentIndexHighest} to 1
	while true = true:
		set {_currentString} to {_s}.substring({_currentIndexLowest}, {_currentIndexHighest})
		loop {Patterns::*}:
			if {_currentString}.matches(loop-value) = true:
				add Token(loop-index, {_currentString}) to {_tokens::*}
				broadcast "&c%Token(loop-index, {_currentString})%"
				set {_currentIndexLowest} to {_currentIndexHighest}
				broadcast "%loop-index% match"
				exit 1 loop 
				
			if {_isExpressionParsing} = true:
				if {_currentString}.matches("%%[a-z| ]+%%"):
					add Token({_currentString}.substring(1, {_currentString}.length() - 1), "ðŸ—¿") to {_tokens::*}
					set {_currentIndexLowest} to {_currentIndexHighest}
					exit 1 loop 
		
		add 1 to {_currentIndexHighest}
		if {_currentIndexHighest} > {_length}:
			if {_currentIndexLowest} >= {_length}:
				stop loop 
			add Token("Literal", {_s}.charAt({_currentIndexLowest})) to {_tokens::*}
			add 1 to {_currentIndexLowest}
			set {_currentIndexHighest} to {_currentIndexLowest} + 1
		
			
		add 1 to {_EEE}
		if {_EEE} >= 1000:
			broadcast "uh oh"
			stop loop
			
	set {_tokens::*} to Merge({_tokens::*}, ("Literal", "Indentation", "Number"))
	broadcast "&cTOKENZ: %{_tokens::*}%"
	return {_tokens::*}
	
function Merge(o: objects, tokenType: strings, n: number=0) :: nbt compounds:
	if {_n} >= 1000:
		broadcast "Merge %{_tokenType}% Limit Reached"
		stop
	if size of {_tokenType::*} != 1:
		loop {_tokenType::*}:
			set {_o::*} to Merge({_o::*}, loop-value, 0)
		return {_o::*}
	set {_tokenType} to {_tokenType::1}
	loop ((size of {_o::*} - 1) times):
		if TokenType({_o::%loop-value%}) != {_tokenType}:
			continue
		if TokenType({_o::%loop-value%}) = TokenType({_o::%loop-value + 1%}):
			SetTokenValue({_o::%loop-value%}, join (TokenValue({_o::%loop-value%}), TokenValue({_o::%loop-value + 1%})))
			delete {_o::%loop-value + 1%}
			return Merge({_o::*}, {_tokenType}, {_n} + 1)
	return {_o::*}
	
function ExpressionToken(expressionName: string, o: nbt compounds) :: nbt compound:
	set {_nbt} to nbt from "{}"
	loop {_o::*}:
		if TokenType(loop-value) != "Literal", "Space" or "Indentation":
			add 1 to {_n}
			set compound tag "%{_n}%" of {_nbt} to loop-value
	set string tag "ExpressionName" of {_nbt} to {_expressionName}
	return {_nbt}
	
function HandleExpressions(o: nbt compounds) :: nbt compounds:
	set {_length} to size of {_o::*}
	set {_currentIndexLowest} to 1
	set {_currentIndexHighest} to 1
	while true = true:
		set {_currentTokens::*} to elements from {_currentIndexLowest} to {_currentIndexHighest} of {_o::*}
		
		loop (indexes of {ExpressionTokens::*}):
			set {_loopTokens::*} to {ExpressionTokens::%loop-value%::*}
			if size of {_loopTokens::*} != (size of {_currentTokens::*}):
				continue
			set {_success} to true
			loop {_loopTokens::*}:
				set {_cToken} to {_currentTokens::%loop-index%}
				if TokenType({_cToken}) != TokenType(loop-value-2):
					if TokenType({_cToken}) != "Variable":
						set {_success} to false
						exit 1 loop 
				set {_value} to TokenValue({_CToken})
				set {_value2} to TokenValue(loop-value-2)
				if {_value} != {_value2}:
					set {_type} to TokenType({_cToken})
					if {_type} = "Literal":
						set {_success} to false
						exit 1 loop 
			if {_success} = true:
				set {_expressionToken} to ExpressionToken(loop-value-1, {_currentTokens::*})
				loop (integers between {_currentIndexLowest} and {_currentIndexHighest}):
					delete {_o::%loop-value-2%}
				broadcast "%{_expressionToken}% &e- %loop-value%"
				run section {ExpressioInfo::%loop-value%::Convertion} with {_expressionToken} and store result in {_b}
				set {_o::%{_currentIndexLowest}%} to Token({ExpressionInfo::%loop-value%::Type}, {_b})
				broadcast "&bTest: %{_b}%"
				return HandleExpressions({_o::*})
				
		
		add 1 to {_currentIndexHighest}
		if {_currentIndexHighest} > {_length}:
			if {_currentIndexLowest} > {_length}:
				broadcast "E %{_length}% - %{_currentIndexHighest}% - %{_currentIndexLowest}%"
				stop loop 
			add Token("Literal", {_s}.charAt({_currentIndexLowest})) to {_tokens::*}
			add 1 to {_currentIndexLowest}
			set {_currentIndexHighest} to {_currentIndexLowest} + 1
		
			
		add 1 to {_EEE}
		if {_EEE} >= 1000:
			stop loop
	return {_o::*}
	
function HandleEffects(o: nbt compounds) :: strings:
	loop (indexes of {EffectTokens::*}):
		set {_tokens::*} to {EffectTokens::%loop-value%::*}
		if size of {_tokens::*} != size of {_o::*}:
			continue 
		set {_success} to true
		loop {_o::*}:
			set {_cToken} to {_tokens::%loop-index%}
			if TokenType({_cToken}) != TokenType(loop-value-2):
				if TokenType({_cToken}) != "Variable" or "Object":
					set {_success} to false
					exit 1 loop 
			set {_value} to TokenValue({_CToken})
			set {_value2} to TokenValue(loop-value-2)
			if {_value} != {_value2}:
				set {_type} to TokenType({_cToken})
				if {_type} = "Literal":
					set {_success} to false
					exit 1 loop 
		if {_success} = false:
			continue 
		broadcast "&b%{_success}%"
		run section {EffectInfo::%loop-value%::Convertion} with ({_o::*} where [TokenType(input) != "Literal" or "Space"]) and store result in {_b}
		add {_b} to {_r::*}
	return {_r::*}
		
		
	
function ConvertToSyntax(s: string) :: nbt compounds:
	return Tokenised({_s}, true)
	
function TokenValueToVar(s: string) :: string:
	return join """", {_s}.substring(1, (length of {_s} - 1)), """"
on load:
	delete {Patterns::*}, {ExpressionTokens::*}, {ExpressionInfo::*}
	delete {ExpressionTokens::*}
	
	set {Patterns::String} to """[^\s]+"""
	set {Patterns::Variable} to "\{[^\s]+}"
	set {Patterns::Number} to "[0-9]+"
	set {Patterns::Space} to " "
	set {Patterns::Indentation} to "	"
	set {ExpressionTokens::StringLength::*} to ConvertToSyntax("length of %%string%%")
	set {ExpressionInfo::StringLength::Type} to "number"
	set {ExpressionInfo::StringLength::IsSingle} to true
	create section with {_expressionToken} stored in {ExpressioInfo::StringLength::Convertion}:
		set {_token} to compound tag "1" of {_expressionToken}
		if TokenType({_token}) = "string":
			return "%length of TokenValue({_token}) - 2%"
		else:
			return "Variables.getString(%TokenValueToVar(TokenValue({_token}))%).length()"
			
	set {EffectTokens::Broadcast::*} to ConvertToSyntax("broadcast %%object%%")
	create section with {_tokens::*} stored in {EffectInfo::Broadcast::Convertion}:
		return "Bukkit.broadcastMessage(%TokenValue({_tokens::1})%);"
		
	set {EffectTokens::OnLoad::*} to ConvertToSyntax("on load:")
	create section with {_tokens::*} stored in {EffectInfo::OnLoad::Convertion}:
		return "public static void main(String[] args)"
		
	set {EffectTokens::Loop::*} to ConvertToSyntax("loop %%number%% times:")
	create section with {_tokens::*} stored in {EffectInfo::Loop::Convertion}:
		return "for (int i = 0; i < %TokenValue({_tokens::1})%; i++)"
		
	set {_l::*} to "on load:", "	loop 10 times:", "		broadcast length of ""test""", "	broadcast ""test"""
	set {_lastIndentationAmount} to 0
	
	set {_imports::1} to "org.bukkit.Bukkit"
	loop {_imports::*}:
		set {_imports::%loop-index%} to "import %loop-value%;%nl%"
	set {_import} to join {_imports::*}
	set {_autoGen} to "// This class has been automatically generated.%nl%// Version: beta-1"
	set {_body} to join {_import}, {_autoGen}, nl, "class Main {%nl%"
	
	loop {_l::*}:
		set {_tokens::*} to Tokenise(loop-value)
		set {_indentationAmount} to 0
		if TokenType({_tokens::1}) = "indentation":
			set {_indentationAmount} to length of TokenValue({_tokens::1})
			delete {_tokens::1}
		
		set {_tab} to ""
		loop ({_indentationAmount} + 1) times:
			set {_tab} to join {_tab}, "    "
			
		set {_iClone} to {_indentationAmount}
		
		if {_indentationAmount} != {_lastIndentationAmount}:
			while {_indentationAmount} > {_lastIndentationAmount}:
				remove 1 from {_indentationAmount}
				set {_body} to join {_body}, " {"
			while {_indentationAmount} < {_lastIndentationAmount}:
				add 1 to {_indentationAmount}
				set {_tab} to ""
				loop ({_indentationAmount}) times:
					set {_tab} to join {_tab}, "    "
				set {_body} to join {_body}, nl, {_tab}, "}"
		
		set {_tokens::*} to HandleExpressions({_tokens::*})
		set {_body} to join {_body}, nl, {_tab}, HandleEffects({_tokens::*})
		
		set {_lastIndentationAmount} to {_iClone}
		
		
	loop {_lastIndentationAmount} times:
		set {_tab} to ""
		loop ({_lastIndentationAmount} - loop-value + 1) times:
			set {_tab} to join {_tab}, "    "
		broadcast "tab: %length of {_tab}%"
		set {_body} to join {_body}, nl, "%{_tab}%}"
		
	broadcast "IND: %{_lastIndentationAmount}%"
	set {_body} to join {_body}, "%nl%}"
	
	broadcast {_body}
	
	
	
